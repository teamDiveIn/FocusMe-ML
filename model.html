<!-- 
    테스트 버전 모델
    init() 함수를 실행하면 웹캠 on, 작동 시작
    prediction()에서 예측 수행

    현재 기능은 화면을 똑바로 보는 자세인지, 혹은 옆을 보고 있거나 화면에 사람이 없는지를 분류
    (아직 정확도가 낮음)
    (화면을 똑바로 보고, 어깨까지 나와야 화면 보는 걸로 인식)
-->

<!-- html -->
<!-- 
    html에서 init()함수를 선언하여 기능 시작
    #canvas에 웹캠 화면 및 키포인트&스켈레톤 뿌림
    #label-container에 예측 결과 뿌림
-->

<h1>테스트 모델</h1>
<button type="button" onclick="init()">Start</button>
<div><canvas id="canvas"></canvas></div>
<div id="label-container"></div>

<!-- emoji를 html img element 로 넘겨줘야 함-->
<div style="display:none;">
    <img id="source" src="http://pngimg.com/uploads/google/google_PNG19635.png">
</div>
  
<!-- javascript -->
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.3.1/dist/tf.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@teachablemachine/pose@0.8/dist/teachablemachine-pose.min.js"></script>
<script type="text/javascript">
    // Model URL
    // const URL = "https://teachablemachine.withgoogle.com/models/3p4QdqNUG/"; // test ver
    const URL = "https://teachablemachine.withgoogle.com/models/B9S7LxtSs/" // 상하좌우
    let model, webcam, ctx, labelContainer, maxPredictions;

    async function init() {
        const modelURL = URL + "model.json";
        const metadataURL = URL + "metadata.json";

        model = await tmPose.load(modelURL, metadataURL);
        maxPredictions = model.getTotalClasses();

        const size = 200; // webcam 사이즈
        const flip = true; // webcam 좌우 반전 flip 설정
        webcam = new tmPose.Webcam(size, size, flip); // webcam 생성
        await webcam.setup(); // request access to the webcam
        await webcam.play();
        window.requestAnimationFrame(loop);

        // canvas에 웹캠 그리기
        const canvas = document.getElementById("canvas");
        canvas.width = size; canvas.height = size;
        ctx = canvas.getContext("2d");

        // 예측결과 표시할 div
        labelContainer = document.getElementById("label-container");
        for (let i = 0; i < maxPredictions; i++) { // and class labels
            labelContainer.appendChild(document.createElement("div"));
        }
    }

    async function loop(timestamp) {
        webcam.update(); // update the webcam frame
        await predict(); // 추론 수행
        window.requestAnimationFrame(loop);
    }

    async function predict() {
        // Prediction #1: 입력 이미지에서 pose 추론
        // estimatePose can take in an image, video or canvas html element
        const { pose, posenetOutput } = await model.estimatePose(webcam.canvas);
        // Prediction 2: pose를 classification (어떤 포즈인지)
        const prediction = await model.predict(posenetOutput);

        // prediction에 결과 저장

        for (let i = 0; i < maxPredictions; i++) {
            const classPrediction =
                prediction[i].className + ": " + prediction[i].probability.toFixed(2);
            labelContainer.childNodes[i].innerHTML = classPrediction;
        }
        // 0번째 클래스 (집중하는 중)의 확률을 수로 받아오기
        //console.log(prediction[0].probability);

        // 각 부위의 x,y 좌표 받아오기
        // 0: nose 1: leftEye 2:rightEye 3:leftEar 4:rightEar 5:leftShoulder 6:rightShoulder
        //console.log(pose.keypoints[0].position);

        drawEmoji(pose, prediction); // 이모지 그리는 함수

        // 포즈 스켈레톤 그리기 (선택사항)
        //drawPose(pose);
    }

    function drawEmoji(pose, prediction) {
        const image = document.getElementById('source'); // htmlImgElement 가져오기
        argmax = 0;
        maxval = 0;
        // 시선 방향 얻기 (argmax)
        for (let i = 0; i < maxPredictions; i++) {
            if (prediction[i].probability > maxval) {
                maxval = prediction[i].probability;
                argmax = i;
            }
        }
        if (webcam.canvas) {
            ctx.drawImage(webcam.canvas, 0, 0); // 웹캠 화면 그리기
            if (pose) {
                right = pose.keypoints[2].position.x;
                left = pose.keypoints[1].position.x;
                faceSize = right-left;
                center = pose.keypoints[0].position;
                const minPartConfidence = 0.5;
                // argmax에 따라 다른 이모지 출력하는 코드 여기 작성
                ctx.drawImage(image, center.x - faceSize, center.y - faceSize, faceSize*2, faceSize*2); // 이모지 그리기 (뒤에 숫자는 사이즈)
            }
        }
    }

    function drawPose(pose) {
        if (webcam.canvas) {
            ctx.drawImage(webcam.canvas, 0, 0);
            // 키포인트와 스켈레톤 그리기
            if (pose) {
                const minPartConfidence = 0.5;
                tmPose.drawKeypoints(pose.keypoints, minPartConfidence, ctx);
                tmPose.drawSkeleton(pose.keypoints, minPartConfidence, ctx);
            }
        }
    }
</script>
